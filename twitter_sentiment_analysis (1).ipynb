{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "twitter_sentiment_analysis.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yveFAg68umBV",
        "outputId": "a9646e5b-b079-444b-e4b7-21a19fd7a312"
      },
      "source": [
        "#importing modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import regex as re\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2zmdV_fuvQG",
        "outputId": "be6604d7-9829-4789-e89a-201695686cd6"
      },
      "source": [
        "#importing dataset\n",
        "df = pd.read_csv(\"/content/data.csv\", encoding=\"ISO-8859-1\")\n",
        "print(df.columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['sentiment', 'text', 'user'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WE9Ji6udu11t"
      },
      "source": [
        "#dropping useless columns\n",
        "df = df.drop([\"user\"], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xg3EWWpVu9Ne",
        "outputId": "e603bd58-13a9-4011-8f9f-be48a786ed09"
      },
      "source": [
        "#get the unique values of sentiment column\n",
        "print(df[\"sentiment\"].unique())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['positive' 'neutral' 'negative']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHHy9UIJwacx"
      },
      "source": [
        "#get the probability of a tweet being positive, negative or neutral\n",
        "prob_positive = len([tweet for tweet in df[\"sentiment\"] if tweet == 'positive']) / len(df)\n",
        "prob_neutral = len([tweet for tweet in df[\"sentiment\"] if tweet == 'neutral']) / len(df)\n",
        "prob_negative = len([tweet for tweet in df[\"sentiment\"] if tweet == 'negative']) / len(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8lJJGCrwjpZ"
      },
      "source": [
        "#clean the tweets by removing the hashtags, mentions, non-english alphabets and other links\n",
        "texts = []\n",
        "for text in df[\"text\"]:\n",
        "  text = re.sub(r\"(^RT\\s+@.*:\\s)\", \"\", text)\n",
        "  text = re.sub(r\"https:.*\", \"\", text)\n",
        "  text = re.sub(r\"(\\s)[#@]+\\w+\", \"\", text) #removing all mentions and hashtags that occur in middle of tweets\n",
        "  text = re.sub(r\"([#@]+\\w+\\s)\", \"\", text) #removing all mentions and hashtags that occur at the starting of tweets\n",
        "  text = re.sub(r\"[,.?!]*\", \"\", text)\n",
        "  text = re.sub(r\"[^a-zA-Z\\s']+\", \"\", text) #removing words that contain characters other than english alphabets and spaces.\n",
        "  texts.append(text)\n",
        "df[\"text\"] = texts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ye6mY-PXwzbb"
      },
      "source": [
        "#merge the positive tweets together. Do the same for negative and neutral tweets also.\n",
        "positive_tweets_list = []\n",
        "negative_tweets_list = []\n",
        "neutral_tweets_list = []\n",
        "for (label, tweet) in zip(df[\"sentiment\"], df[\"text\"]):\n",
        "  if label == 'positive':\n",
        "    positive_tweets_list.append(tweet)\n",
        "  elif label == 'negative':\n",
        "    negative_tweets_list.append(tweet)\n",
        "  else:\n",
        "    neutral_tweets_list.append(tweet)\n",
        "\n",
        "positive_tweets = \" \".join(positive_tweets_list)\n",
        "negative_tweets = \" \".join(negative_tweets_list)\n",
        "neutral_tweets = \" \".join(neutral_tweets_list)\n",
        "\n",
        "#Create a string that contains all the tweets too.\n",
        "all_tweets = positive_tweets + \" \" + negative_tweets + \" \" + neutral_tweets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QSgVq2BxES4"
      },
      "source": [
        "#define a function that returns the bag of words while removing stopwords and stemming the words as well.\n",
        "#bag of words is dictionary where each word is stored with the no of times it appears in the text.\n",
        "def bag_of_words(sentence):\n",
        "  bag = {}\n",
        "  ps = PorterStemmer()\n",
        "  #sw = stopwords.words('english')\n",
        "  for word in sentence.lower().split():\n",
        "    #word = ps.stem(word)\n",
        "    #if word in sw:\n",
        "      #pass\n",
        "    if word in bag:\n",
        "      bag[word] += 1\n",
        "    else:\n",
        "      bag[word] = 1\n",
        "  return bag"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49ougcaixZLT"
      },
      "source": [
        "#create a bag of words for the negative, positive and neutral tweets separately.\n",
        "negative_words = bag_of_words(negative_tweets)\n",
        "positive_words = bag_of_words(positive_tweets)\n",
        "neutral_words = bag_of_words(neutral_tweets)\n",
        "\n",
        "#create a bag of words for all tweets combined too.\n",
        "all_words = bag_of_words(all_tweets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpjFege7xwBM"
      },
      "source": [
        "#predict the sentiment by calculating probabilities for each sentiment using naive bayes formula\n",
        "def predict(sentence):\n",
        "  positive_prob = 1\n",
        "  negative_prob = 1\n",
        "  neutral_prob = 1\n",
        "  for word in sent.split():\n",
        "\n",
        "    if word in positive_words:\n",
        "      prob_word_is_positive = (positive_words[word] + 1)/ (sum(positive_words.values()) + 1) \n",
        "    else:\n",
        "      prob_word_is_positive = 1 / (sum(positive_words.values()) +1)\n",
        "\n",
        "    if word in all_words:\n",
        "      prob_word = (all_words[word] + 1) / (sum(all_words.values()) +1) \n",
        "    else:\n",
        "      prob_word = 1 / (sum(all_words.values()) +1)\n",
        "\n",
        "    if word in negative_words:\n",
        "      prob_word_is_negative = (negative_words[word] + 1) / (sum(negative_words.values()) +1)\n",
        "    else:\n",
        "      prob_word_is_negative = 1 / (sum(negative_words.values()) +1)\n",
        "\n",
        "    if word in negative_words:\n",
        "      prob_word_is_negative = (negative_words[word] + 1) / (sum(negative_words.values()) +1)\n",
        "    else:\n",
        "      prob_word_is_negative = 1 / (sum(negative_words.values()) +1)\n",
        "\n",
        "    if word in neutral_words:\n",
        "      prob_word_is_neutral = (neutral_words[word] + 1) / (sum(neutral_words.values()) +1)\n",
        "    else:\n",
        "      prob_word_is_neutral = 1 / (sum(neutral_words.values()) +1)\n",
        "\n",
        "    positive_prob *= prob_word_is_positive * prob_positive / prob_word\n",
        "    negative_prob *= prob_word_is_negative * prob_negative / prob_word\n",
        "    neutral_prob *= prob_word_is_neutral * prob_neutral / prob_word\n",
        "    print(\"positive: {0:.2f}%\".format(positive_prob*100))\n",
        "    print(\"negative: {0:.2f}%\".format(negative_prob*100))\n",
        "    print(\"neutral: {0:.2f}%\".format(neutral_prob*100))\n",
        "    if neutral_prob > 1:\n",
        "      return \"neutral\"\n",
        "    elif positive_prob >= negative_prob:\n",
        "      return \"positive\"\n",
        "    else:\n",
        "      return \"negative\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_KqM_UuxmH1",
        "outputId": "b876084a-fca6-4467-daa9-e4eb0bed6834"
      },
      "source": [
        "#predicting probabilities of tweet being positive or negative until user types \"bye\"\n",
        "while True:\n",
        "  sent = input(\"Enter a sentence: \")\n",
        "  if sent.lower()==\"bye\":\n",
        "    break\n",
        "  result = predict(sent)\n",
        "  print(\"Sentence is: \", result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter a sentence: hello\n",
            "positive: 43.72%\n",
            "negative: 54.77%\n",
            "neutral: 111.49%\n",
            "Sentence is:  neutral\n",
            "Enter a sentence: this game is annoying\n",
            "positive: 29.15%\n",
            "negative: 62.60%\n",
            "neutral: 21.24%\n",
            "Sentence is:  negative\n",
            "Enter a sentence: sachin is a legendary cricketer\n",
            "positive: 87.44%\n",
            "negative: 54.77%\n",
            "neutral: 55.75%\n",
            "Sentence is:  positive\n",
            "Enter a sentence: bye\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RF0P6lJ3yYnc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}